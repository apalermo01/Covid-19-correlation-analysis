{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# import classes\n",
    "import Coviddataclass as cd\n",
    "\n",
    "# fontsizes for plots\n",
    "BIG_TEXT   = 18\n",
    "MED_TEXT   = 14\n",
    "SMALL_TEXT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\Documents\\GitHub\\covid-19-data-analysis\\Coviddataclass.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['new_cases_7day'][df['date'] < pd.to_datetime('2020-01-30', format='%Y-%m-%d')] =\\\n",
      "C:\\Users\\alexc\\Documents\\GitHub\\covid-19-data-analysis\\Coviddataclass.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['new_deaths_7day'][df['date'] < pd.to_datetime('2020-01-30', format='%Y-%m-%d')] =\\\n"
     ]
    }
   ],
   "source": [
    "# load and clean data\n",
    "df  = pd.read_csv('https://query.data.world/s/jbgdegbanosfmgly7etz2gxqsbhflk')\n",
    "df2 = pd.read_csv('state_policy_updates_20201114_0719.csv')\n",
    "data_manager = cd.Coviddataclass()\n",
    "\n",
    "df, df2 = data_manager.clean_data(df, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlate COVID-19 responses at the state and local level with the number of new cases and deaths at a variable time (14 days by default). This will use the 7 day average at the date in question to avoid outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deltas(measure_period=14, filtered_policies=None, case_df=df, policy_df=df2):\n",
    "    \"\"\"For every policy implementation at the state and county level, calculate the change in case and death numbers. \n",
    "    inputs: \n",
    "    measure_period    -- time to wait\n",
    "    min_samples       -- minimum number of samples\n",
    "    filtered_policies -- selected policies to select\n",
    "    \n",
    "    returns: \n",
    "    A copy of the df (covid policies) dataframe with 2 appended columns for the change in case and death numbers. \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize wait period before measurement\n",
    "    wait_period = datetime.timedelta(days=measure_period) # time in days to watch change in case / death number\n",
    "    day_1 = datetime.timedelta(days=1)\n",
    "    \n",
    "    # filter policies if needed and make a 2 copies of the original policies dataframe- one for iteration and another \n",
    "    # for modification\n",
    "    \n",
    "    if filtered_policies is not None: \n",
    "        all_policies  = policy_df.loc[policy_df['policy_type'].isin(filtered_policies)]\n",
    "        policy_deltas = policy_df.loc[policy_df['policy_type'].isin(filtered_policies)]\n",
    "    else: \n",
    "        all_policies  = policy_df.copy()\n",
    "        policy_deltas = policy_df.copy()\n",
    "    \n",
    "    # initially fill the delta column with nan\n",
    "    policy_deltas.loc[:, f\"case_{measure_period}_day_delta\"] = np.nan\n",
    "    policy_deltas.loc[:, f\"case_{measure_period}_day_accel\"] = np.nan\n",
    "    policy_deltas.loc[:, f\"death_{measure_period}_day_delta\"] = np.nan\n",
    "    policy_deltas.loc[:, f\"death_{measure_period}_day_accel\"] = np.nan\n",
    "    \n",
    "    i=0 # counter to time the loop\n",
    "    state_cases_dict = dict()\n",
    "\n",
    "    # load all state-aggregated datasets into a dictionary\n",
    "    print(\"aggregating state data\")\n",
    "    for state in policy_df['state_id'].unique(): \n",
    "        state_cases_dict[state]=data_manager.get_cases(df=case_df, level=\"state\", state=state)\n",
    "    \n",
    "    print(\"aggregating state data complete\")\n",
    "        \n",
    "    # loop through all policies in the policy dataset\n",
    "    for index, data in all_policies.iterrows(): \n",
    "\n",
    "        # handle state info\n",
    "        if data.policy_level == \"state\": \n",
    "            policy_case_df = state_cases_dict[data.state_id]\n",
    "\n",
    "        # handle county info\n",
    "        else: \n",
    "            policy_case_df = data_manager.get_cases(df=case_df, level=\"county\", county=data.county, state=data.state_id)\n",
    "\n",
    "        # output status updates since this loop takes a long time (~3 minutes)\n",
    "        i += 1\n",
    "        if i%100 == 0: \n",
    "            print(f\"record {i}/{len(all_policies.index)}\")\n",
    "        policy_date = pd.to_datetime(data['date'])\n",
    "        measure_date = policy_date + wait_period\n",
    "        \n",
    "        # pass if the measure date is within 3 days (gives the case data time to update)\n",
    "        if measure_date > pd.Timestamp.today() - datetime.timedelta(days=3): \n",
    "            continue\n",
    "        \n",
    "        # calculate \"velocity\" of covid cases\n",
    "        cases_start  = policy_case_df[policy_case_df.index==policy_date ]['new_cases_7day_1e6' ].values\n",
    "        cases_end    = policy_case_df[policy_case_df.index==measure_date]['new_cases_7day_1e6' ].values\n",
    "        deaths_start = policy_case_df[policy_case_df.index==policy_date ]['new_deaths_7day_1e6'].values\n",
    "        deaths_end   = policy_case_df[policy_case_df.index==measure_date]['new_deaths_7day_1e6'].values\n",
    "\n",
    "        delta_cases  = cases_end  - cases_start\n",
    "        delta_deaths = deaths_end - deaths_start\n",
    "        \n",
    "        policy_deltas.at[index, f\"case_{measure_period}_day_delta\"]  = delta_cases\n",
    "        policy_deltas.at[index, f\"death_{measure_period}_day_delta\"] = delta_deaths\n",
    "        \n",
    "        # calculate \"acceleration\" of covid cases\n",
    "        # (velocity at end of measure period - velocity at start) / measure period \n",
    "        c11 = policy_case_df[policy_case_df.index==measure_date       ]['new_cases_7day_1e6' ].values\n",
    "        c12 = policy_case_df[policy_case_df.index==measure_date+day_1 ]['new_cases_7day_1e6' ].values\n",
    "        \n",
    "        c21 = policy_case_df[policy_case_df.index==policy_date        ]['new_cases_7day_1e6' ].values\n",
    "        c22 = policy_case_df[policy_case_df.index==policy_date+day_1  ]['new_cases_7day_1e6' ].values\n",
    "        \n",
    "        d11 = policy_case_df[policy_case_df.index==measure_date       ]['new_deaths_7day_1e6'].values\n",
    "        d12 = policy_case_df[policy_case_df.index==measure_date+day_1 ]['new_deaths_7day_1e6'].values\n",
    "        \n",
    "        d21 = policy_case_df[policy_case_df.index==policy_date        ]['new_deaths_7day_1e6'].values\n",
    "        d22 = policy_case_df[policy_case_df.index==policy_date+day_1  ]['new_deaths_7day_1e6'].values\n",
    "        \n",
    "        case_accel   = ((c12-c11) - (c21-c22)) / measure_period\n",
    "        deaths_accel = ((d12-d11) - (d21-d22)) / measure_period\n",
    "        \n",
    "        policy_deltas.at[index, f\"case_{measure_period}_day_accel\"]  = case_accel\n",
    "        policy_deltas.at[index, f\"death_{measure_period}_day_accel\"] = deaths_accel\n",
    "        \n",
    "    return policy_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregating state data\n",
      "aggregating state data complete\n",
      "record 100/3415\n",
      "record 200/3415\n",
      "record 300/3415\n",
      "record 400/3415\n",
      "record 500/3415\n",
      "record 600/3415\n",
      "record 700/3415\n",
      "record 800/3415\n",
      "record 900/3415\n",
      "record 1000/3415\n",
      "record 1100/3415\n",
      "record 1200/3415\n",
      "record 1300/3415\n",
      "record 1400/3415\n",
      "record 1500/3415\n",
      "record 1600/3415\n"
     ]
    }
   ],
   "source": [
    "policy_deltas = calculate_deltas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
